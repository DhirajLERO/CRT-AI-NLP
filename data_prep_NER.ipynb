{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:41:32.121417Z",
     "start_time": "2024-06-06T15:41:32.117071Z"
    }
   },
   "outputs": [],
   "source": [
    "import myutils\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "from transformers import tokenization_utils\n",
    "\n",
    "\n",
    "def is_split(char):\n",
    "    return tokenization_utils._is_whitespace(char) or tokenization_utils._is_punctuation(char)\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "def write(data, path):\n",
    "    outfile = open(path,  'w')\n",
    "    for sent in data:\n",
    "        for line in sent:\n",
    "            outfile.write('\\t'.join(line) + '\\n')\n",
    "        outfile.write('\\n')\n",
    "    outfile.close()\n",
    "\n",
    "def fix_bio(data, column):\n",
    "    for rowIdx in reversed(range(1,len(data))):\n",
    "        if data[rowIdx][column] != 'O':\n",
    "            if data[rowIdx][column] != data[rowIdx-1][column]:\n",
    "                data[rowIdx][column] = 'B-' + data[rowIdx][column]\n",
    "            else:\n",
    "                data[rowIdx][column] = 'I-' + data[rowIdx][column]\n",
    "    if data[0][column] != 'O':\n",
    "        data[0][column] = 'B-' + data[0][column]\n",
    "    return data\n",
    "\n",
    "def convert(in_path, out_path):\n",
    "    trainFile = in_path\n",
    "    data = []\n",
    "    with open(trainFile) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        next(reader)\n",
    "        data = []\n",
    "        for rowIdx, row in enumerate(reader):\n",
    "            subreddit_id = row[1]\n",
    "            text = row[-1]\n",
    "            post_id = row[0]\n",
    "            subreddit_id = row[1]\n",
    "            if '[deleted' in text or '[remove' in text:\n",
    "                continue\n",
    "            #print(text[:100])\n",
    "\n",
    "            if 'test' in in_path:\n",
    "                annotations = {}\n",
    "            else:\n",
    "                annotations = json.loads(row[-2])[0]['crowd-entity-annotation']['entities']\n",
    "\n",
    "\n",
    "            annotations_skip = []\n",
    "            skip = False\n",
    "\n",
    "            for annotation in annotations:\n",
    "                ann_beg = annotation['startOffset']\n",
    "                ann_end = annotation['endOffset']\n",
    "                ann_txt = text[ann_beg:ann_end]\n",
    "                if ann_txt in ['[deleted]', '']:\n",
    "                    annotations_skip.append(True)\n",
    "                elif ann_end > len(text) + 1:\n",
    "                    annotations_skip.append(True)\n",
    "                else:\n",
    "                    if ann_beg != 0 and not is_split(text[ann_beg]) and not is_split(text[ann_beg-1]):\n",
    "                        annotations_skip.append(True)\n",
    "                    elif ann_end < len(text) and not is_split(text[ann_end]) and not is_split(text[ann_end+1]) and not is_split(text[ann_end-1]):\n",
    "                        annotations_skip.append(True)\n",
    "                    else:\n",
    "                        annotations_skip.append(False)\n",
    "            if True in annotations_skip:\n",
    "                continue\n",
    "            #    print(annotations_skip)\n",
    "\n",
    "            #print(text)\n",
    "            #print('=-=========')\n",
    "            #for annotation in annotations:\n",
    "            #    print(annotation)\n",
    "    \n",
    "            for annotation in annotations:\n",
    "                begLabel = annotation['startOffset']\n",
    "                endLabel = annotation['endOffset']\n",
    "                #print(text[begLabel:endLabel])\n",
    "            tok = text.split(' ')\n",
    "            charIdx = 0\n",
    "            conll = []\n",
    "            #if 'st2' in in_path:\n",
    "            #    for token in row[2].split(' '):\n",
    "            #        if token != '':\n",
    "            #            conll.append([myutils.clean_text(token), 'O', str(token.encode()), post_id, subreddit_id])\n",
    "            #    conll.append(['[SEP]', 'O'])\n",
    "            for wordIdx in range(len(tok)):\n",
    "                label = 'O'\n",
    "                beg = charIdx + 1\n",
    "                end = charIdx + len(tok[wordIdx])\n",
    "                for annotation in annotations:\n",
    "                    begLabel = annotation['startOffset']\n",
    "                    endLabel = annotation['endOffset']\n",
    "                    if (end > begLabel and end <= endLabel) or (beg >= begLabel and beg < endLabel):\n",
    "                        label = annotation['label']\n",
    "                charIdx += 1 + len(tok[wordIdx])\n",
    "                conll.append([myutils.clean_text(tok[wordIdx]), label,str( tok[wordIdx].encode()), post_id, subreddit_id] )\n",
    "\n",
    "            #data.append(fix_bio(conll, 1))\n",
    "            data.append(conll)\n",
    "    #for sentence in data:\n",
    "    #    for line in sentence:\n",
    "    #        print('\\t'.join(line))\n",
    "    #    print()\n",
    "        \n",
    "    split = int(.8*len(data))\n",
    "    print(out_path, len(data))\n",
    "    if 'test' not in in_path: \n",
    "        write(data[:split], out_path + '-train')\n",
    "        write(data[split:], out_path + '-dev')\n",
    "    write(data, out_path + '-all')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st1_train.conll 4848\n",
      "st1_test.conll 1251\n"
     ]
    }
   ],
   "source": [
    "\n",
    "convert('../st1_train_inc_text.csv', 'st1_train.conll')\n",
    "\n",
    "convert('../st1_test_inc_text.csv', 'st1_test.conll')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T13:12:17.503473Z",
     "start_time": "2024-06-06T13:12:15.842314Z"
    }
   },
   "id": "44a1ff259327ed40",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_conll(path, ann_col):\n",
    "    curSent = []\n",
    "    data = []\n",
    "    for line in open(path):\n",
    "        if len(line) < 2:\n",
    "            data.append(curSent)\n",
    "            curSent = []\n",
    "        else:\n",
    "            tok = line.strip().split('\\t')\n",
    "            word = tok[0]\n",
    "            ann = tok[ann_col]\n",
    "            curSent.append([word, ann])\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:41:44.885737Z",
     "start_time": "2024-06-06T15:41:44.880353Z"
    }
   },
   "id": "8184351be389056d",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = read_conll('st1_train.conll-train', 1)\n",
    "val_data = read_conll('st1_train.conll-dev', 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:41:45.861829Z",
     "start_time": "2024-06-06T15:41:45.274533Z"
    }
   },
   "id": "746246d0fe0a276e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "3878"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:41:48.497183Z",
     "start_time": "2024-06-06T15:41:48.494949Z"
    }
   },
   "id": "fda8db67aa25f894",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class_id = {'per_exp': 0, 'claim_per_exp': 1, 'question': 2, 'claim' : 3, 'O': 4 }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:41:49.018835Z",
     "start_time": "2024-06-06T15:41:49.016805Z"
    }
   },
   "id": "a4b8ce6feaa3bc65",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_list = []\n",
    "for num, i in enumerate(train_data):\n",
    "    # print(num)\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "    for j in i:\n",
    "        try:\n",
    "            tag_list.append(class_id[j[1]])\n",
    "            word_list.append(j[0])\n",
    "        except KeyError as e:\n",
    "            continue\n",
    "    train_data_list.append({'word': word_list, 'tag': tag_list})\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:41:51.245593Z",
     "start_time": "2024-06-06T15:41:51.202295Z"
    }
   },
   "id": "760e1daeb0b72a70",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "val_data_list = []\n",
    "for num, i in enumerate(val_data):\n",
    "    # print(num)\n",
    "    word_list = []\n",
    "    tag_list = []\n",
    "    for j in i:\n",
    "        try:\n",
    "            tag_list.append(class_id[j[1]])\n",
    "            word_list.append(j[0])\n",
    "        except KeyError as e:\n",
    "            continue\n",
    "    val_data_list.append({'word': word_list, 'tag': tag_list})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:41:51.518732Z",
     "start_time": "2024-06-06T15:41:51.513471Z"
    }
   },
   "id": "54923fe0112b0642",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(3878, 970)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_list), len(val_data_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:41:52.145977Z",
     "start_time": "2024-06-06T15:41:52.143614Z"
    }
   },
   "id": "4f7b291689e1a431",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'word': ['How',\n  'long',\n  'does',\n  'it',\n  'take',\n  'to',\n  'drop',\n  'UA',\n  'through',\n  'diet/exerciseHey',\n  'guys,',\n  'I',\n  'had',\n  'my',\n  'first',\n  'flare',\n  'up',\n  'over',\n  'a',\n  'week',\n  'ago.',\n  'The',\n  'ER',\n  'gave',\n  'me',\n  'colchicine',\n  'and',\n  'im',\n  'doing',\n  'much',\n  'better',\n  'now.A',\n  'few',\n  'days',\n  'after',\n  'my',\n  'attack',\n  'my',\n  'UA',\n  'was',\n  '9.6.',\n  'Today',\n  'I',\n  'received',\n  'an',\n  'Amazon',\n  'tester',\n  'and',\n  \"it's\",\n  'showing',\n  '10.3.',\n  'I',\n  'understand',\n  'that',\n  'it',\n  'drops',\n  'during',\n  'an',\n  'attack,',\n  'but',\n  'I',\n  'was',\n  'surprised',\n  'that',\n  'it',\n  'would',\n  'be',\n  'such',\n  'a',\n  \"difference.I've\",\n  'been',\n  'dieting',\n  'and',\n  'exercising',\n  'to',\n  'try',\n  'and',\n  'prevent',\n  'a',\n  'second',\n  'attack',\n  'while',\n  'I',\n  'wait',\n  'for',\n  'my',\n  'rheumatologist',\n  'appointment.',\n  'My',\n  'question',\n  'is',\n  'how',\n  'long',\n  'does',\n  'it',\n  'take',\n  'for',\n  'diet',\n  'and',\n  'exercise',\n  'to',\n  'have',\n  'any',\n  'effect?'],\n 'tag': [2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  4,\n  4,\n  4,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2]}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_list[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:58:54.286218Z",
     "start_time": "2024-06-06T15:58:54.264679Z"
    }
   },
   "id": "5ee4b4392b322b20",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_dict = {'train': train_data_list, 'validation': val_data_list}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:58:15.695569Z",
     "start_time": "2024-06-06T15:58:15.691155Z"
    }
   },
   "id": "5b23b025d2ed1812",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 2\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:06:34.791435Z",
     "start_time": "2024-06-06T16:06:34.585643Z"
    }
   },
   "id": "20cb6eee0728a5fd",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3878\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset_train = Dataset.from_list(train_data_list, split='train')\n",
    "dataset_validate = Dataset.from_list(val_data_list, split='validation')\n",
    "\n",
    "data_dict = {'train': dataset_train, 'validation': dataset_validate}\n",
    "\n",
    "print(len(dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:01:58.050361Z",
     "start_time": "2024-06-06T16:01:57.989837Z"
    }
   },
   "id": "52f1ba00a4f4288a",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_final = DatasetDict(data_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:01:58.860605Z",
     "start_time": "2024-06-06T16:01:58.858385Z"
    }
   },
   "id": "273be0bffc378fbc",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['word', 'tag'],\n        num_rows: 3878\n    })\n    validation: Dataset({\n        features: ['word', 'tag'],\n        num_rows: 970\n    })\n})"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:02:04.881381Z",
     "start_time": "2024-06-06T16:02:04.875077Z"
    }
   },
   "id": "945be06e2b478db4",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples,  label_all_tokens=True):\n",
    "    tokenized_inputs = tokenizer(examples[\"word\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['tag']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:02:10.329772Z",
     "start_time": "2024-06-06T16:02:10.327945Z"
    }
   },
   "id": "a4a14ba0827a87ac",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3878 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a0a39c4e20741a7a9ab25a4e391f06b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/970 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85b77a3edb92474da2813370b9d28429"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset_final.map(tokenize_and_align_labels, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:02:27.255913Z",
     "start_time": "2024-06-06T16:02:26.394386Z"
    }
   },
   "id": "ebe116f8072b94bc",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['word', 'tag', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 3878\n    })\n    validation: Dataset({\n        features: ['word', 'tag', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 970\n    })\n})"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:02:33.795866Z",
     "start_time": "2024-06-06T16:02:33.788934Z"
    }
   },
   "id": "9dc9b09ba1647f2",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "label_list = ['per_exp', 'claim_per_exp', 'question', 'claim' , 'O']\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:02:42.813340Z",
     "start_time": "2024-06-06T16:02:42.303697Z"
    }
   },
   "id": "6410d898ecf267c5",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/23395885/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Users/23395885/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "metric = load_metric(\"seqeval\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:06:40.369214Z",
     "start_time": "2024-06-06T16:06:39.917997Z"
    }
   },
   "id": "538e9b168750e6de",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:06:42.396614Z",
     "start_time": "2024-06-06T16:06:42.391991Z"
    }
   },
   "id": "5e5ad601bff80ef8",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:06:44.023766Z",
     "start_time": "2024-06-06T16:06:44.008505Z"
    }
   },
   "id": "f0640fa9ccf567af",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 10.02 GB, other allocations: 10.35 GB, max allowed: 20.40 GB). Tried to allocate 89.42 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/transformers/trainer.py:1885\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1883\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1884\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1885\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1886\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1887\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1888\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1890\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/transformers/trainer.py:2279\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2276\u001B[0m         grad_norm \u001B[38;5;241m=\u001B[39m _grad_norm\n\u001B[1;32m   2278\u001B[0m \u001B[38;5;66;03m# Optimizer step\u001B[39;00m\n\u001B[0;32m-> 2279\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2280\u001B[0m optimizer_was_run \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39moptimizer_step_was_skipped\n\u001B[1;32m   2281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optimizer_was_run:\n\u001B[1;32m   2282\u001B[0m     \u001B[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/accelerate/optimizer.py:170\u001B[0m, in \u001B[0;36mAcceleratedOptimizer.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    168\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerate_step_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 170\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator_state\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m==\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mXLA:\n\u001B[1;32m    172\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_state\u001B[38;5;241m.\u001B[39mis_xla_gradients_synced \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     73\u001B[0m instance\u001B[38;5;241m.\u001B[39m_step_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     74\u001B[0m wrapped \u001B[38;5;241m=\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(instance, \u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m---> 75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    387\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    388\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    389\u001B[0m             )\n\u001B[0;32m--> 391\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    394\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/adamw.py:177\u001B[0m, in \u001B[0;36mAdamW.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    174\u001B[0m     amsgrad \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamsgrad\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    175\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 177\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_group\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m     adamw(\n\u001B[1;32m    189\u001B[0m         params_with_grad,\n\u001B[1;32m    190\u001B[0m         grads,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    208\u001B[0m         has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[1;32m    209\u001B[0m     )\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/Desktop/CasualClaimID/pythonProject/.venv/lib/python3.10/site-packages/torch/optim/adamw.py:124\u001B[0m, in \u001B[0;36mAdamW._init_group\u001B[0;34m(self, group, params_with_grad, grads, amsgrad, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001B[0m\n\u001B[1;32m    118\u001B[0m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    119\u001B[0m     torch\u001B[38;5;241m.\u001B[39mzeros((), dtype\u001B[38;5;241m=\u001B[39m_get_scalar_dtype(is_fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m\"\u001B[39m]), device\u001B[38;5;241m=\u001B[39mp\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;241m0.0\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m_get_scalar_dtype())\n\u001B[1;32m    122\u001B[0m )\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Exponential moving average of gradient values\u001B[39;00m\n\u001B[0;32m--> 124\u001B[0m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexp_avg\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros_like\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreserve_format\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;66;03m# Exponential moving average of squared gradient values\u001B[39;00m\n\u001B[1;32m    128\u001B[0m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexp_avg_sq\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros_like(\n\u001B[1;32m    129\u001B[0m     p, memory_format\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mpreserve_format\n\u001B[1;32m    130\u001B[0m )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 10.02 GB, other allocations: 10.35 GB, max allowed: 20.40 GB). Tried to allocate 89.42 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:06:46.459805Z",
     "start_time": "2024-06-06T16:06:45.491016Z"
    }
   },
   "id": "fc2abd33b55cd8e9",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1747eadc8dbdb2a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
